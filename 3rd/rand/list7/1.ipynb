{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1758570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Procent etykietowanych: 0.01\n",
      "K-Means + głosowanie:                         0.6428\n",
      "K-Means + głosowanie + najbliższy centroid:   0.4033\n",
      "k-NN (tylko etykietowane):                    0.2333\n",
      "Pełny nadzorowany (LogReg, 100% etykiet):     1.0000\n",
      "\n",
      " Procent etykietowanych: 0.05\n",
      "K-Means + głosowanie:                         0.7717\n",
      "K-Means + głosowanie + najbliższy centroid:   0.7717\n",
      "k-NN (tylko etykietowane):                    0.8275\n",
      "Pełny nadzorowany (LogReg, 100% etykiet):     1.0000\n",
      "\n",
      " Procent etykietowanych: 0.10\n",
      "K-Means + głosowanie:                         0.7833\n",
      "K-Means + głosowanie + najbliższy centroid:   0.7833\n",
      "k-NN (tylko etykietowane):                    0.9003\n",
      "Pełny nadzorowany (LogReg, 100% etykiet):     1.0000\n",
      "\n",
      " Procent etykietowanych: 0.20\n",
      "K-Means + głosowanie:                         0.7857\n",
      "K-Means + głosowanie + najbliższy centroid:   0.7857\n",
      "k-NN (tylko etykietowane):                    0.9564\n",
      "Pełny nadzorowany (LogReg, 100% etykiet):     1.0000\n",
      "\n",
      "Podsumowanie (frakcja, vote, nearest, kNN, full):\n",
      "(0.01, 0.642791551882461, 0.4032529444756029, 0.2333146382501402, 1.0)\n",
      "(0.05, 0.7717136150234741, 0.7717136150234741, 0.8274647887323944, 1.0)\n",
      "(0.1, 0.7832817337461301, 0.7832817337461301, 0.9003095975232198, 1.0)\n",
      "(0.2, 0.7856640899508082, 0.7856640899508082, 0.9564300773014758, 1.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y_true = digits.target\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "def mask_labeled(y_true, frac_labeled, rng):\n",
    "    n = len(y_true)\n",
    "    mask = rng.rand(n) < frac_labeled\n",
    "    y_semi = np.full_like(y_true, -1)\n",
    "    y_semi[mask] = y_true[mask]\n",
    "    return y_semi, mask\n",
    "\n",
    "full_clf = LogisticRegression(max_iter=1000)\n",
    "full_clf.fit(X, y_true)\n",
    "\n",
    "fractions = [0.01, 0.05, 0.10, 0.20]\n",
    "n_clusters = 10\n",
    "\n",
    "\n",
    "for frac in fractions:\n",
    "    print(f\"\\n Procent etykietowanych: {frac:.2f}\")\n",
    "\n",
    "    # a) losowe ukrycie etykiet\n",
    "    y_semi, labeled_mask = mask_labeled(y_true, frac, rng)\n",
    "    unlabeled_mask = np.logical_not(labeled_mask)\n",
    "\n",
    "    # b) K-Means\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=10)\n",
    "    cluster_ids = kmeans.fit_predict(X)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "\n",
    "    # przypisanie etykiet klastrom przez głosowanie większościowe\n",
    "    cluster_labels = np.full(n_clusters, -1, dtype=int)\n",
    "    for c in range(n_clusters):\n",
    "        in_cluster = (cluster_ids == c) & labeled_mask\n",
    "        if np.any(in_cluster):\n",
    "            vals, counts = np.unique(y_true[in_cluster], return_counts=True)\n",
    "            cluster_labels[c] = vals[np.argmax(counts)]\n",
    "\n",
    "    # c) 1. głosowanie\n",
    "    y_pred_vote = cluster_labels[cluster_ids]\n",
    "    valid_vote_mask = unlabeled_mask & (y_pred_vote != -1)\n",
    "\n",
    "    if np.any(valid_vote_mask):\n",
    "        acc_vote = accuracy_score(y_true[valid_vote_mask], y_pred_vote[valid_vote_mask])\n",
    "    else:\n",
    "        acc_vote = np.nan\n",
    "\n",
    "    # c) 2. najbliższy centroid\n",
    "    missing = cluster_labels == -1\n",
    "    if np.any(missing):\n",
    "        labeled_clusters = np.where(cluster_labels != -1)[0]\n",
    "        for c in np.where(missing)[0]:\n",
    "            dists = np.linalg.norm(centroids[labeled_clusters] - centroids[c], axis=1)\n",
    "            nearest = labeled_clusters[np.argmin(dists)]\n",
    "            cluster_labels[c] = cluster_labels[nearest]\n",
    "\n",
    "    y_pred_nearest = cluster_labels[cluster_ids]\n",
    "    acc_nearest = accuracy_score(y_true[unlabeled_mask], y_pred_nearest[unlabeled_mask])\n",
    "\n",
    "    # kNN\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X[labeled_mask], y_true[labeled_mask])\n",
    "    y_knn = knn.predict(X[unlabeled_mask])\n",
    "    acc_knn = accuracy_score(y_true[unlabeled_mask], y_knn)\n",
    "\n",
    "    # pełny nadzorowany\n",
    "    y_full_pred = full_clf.predict(X[unlabeled_mask])\n",
    "    acc_full = accuracy_score(y_true[unlabeled_mask], y_full_pred)\n",
    "\n",
    "    print(f\"K-Means + głosowanie:                         {acc_vote:.4f}\")\n",
    "    print(f\"K-Means + głosowanie + najbliższy centroid:   {acc_nearest:.4f}\")\n",
    "    print(f\"k-NN (tylko etykietowane):                    {acc_knn:.4f}\")\n",
    "    print(f\"Pełny nadzorowany (LogReg, 100% etykiet):     {acc_full:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
