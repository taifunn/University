{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a21bece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "\n",
    "def generate_sensor_data(n_normal=180, n_anomaly=20, random_state=42):\n",
    "    \"\"\"Generuje dane czujnikow z anomaliami.\"\"\"\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Normalne tramwaje - 3 klastry operacyjne\n",
    "    normal = np.vstack([\n",
    "        np.random.randn(60, 3) * 0.5 + [50, 10, 30],  # temp, vibration, speed\n",
    "        np.random.randn(60, 3) * 0.5 + [55, 12, 35],\n",
    "        np.random.randn(60, 3) * 0.5 + [48, 8, 28],\n",
    "    ])\n",
    "\n",
    "    # Anomalie - nietypowe zachowania\n",
    "    anomalies = np.vstack([\n",
    "        np.random.randn(10, 3) * 0.3 + [80, 25, 15],  # przegrzanie\n",
    "        np.random.randn(10, 3) * 0.3 + [30, 30, 5],   # awaria silnika\n",
    "    ])\n",
    "\n",
    "    X = np.vstack([normal, anomalies])\n",
    "    y_true = np.array([0] * n_normal + [1] * n_anomaly)  # 0 = normal, 1 = anomaly\n",
    "    return X, y_true\n",
    "\n",
    "\n",
    "def detect_anomalies_kmeans(X, k=3, percentile=95):\n",
    "    \"\"\"Wykrywanie anomalii metoda K-Means.\"\"\"\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "    distances = np.min(kmeans.transform(X), axis=1)\n",
    "    tres = np.percentile(distances, percentile)\n",
    "    anomalies = np.where(distances > tres)[0]\n",
    "    return anomalies\n",
    "\n",
    "\n",
    "def detect_anomalies_dbscan(X, eps=5, min_samples=5):\n",
    "    \"\"\"Wykrywanie anomalii metoda DBSCAN.\"\"\"\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    labels = dbscan.fit_predict(X)\n",
    "    anomalies = np.where(labels == -1)[0]\n",
    "    return anomalies\n",
    "\n",
    "def detect_anomalies_lof(X, n_neighbors=20, contamination=0.1):\n",
    "    lof = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination)\n",
    "    labels = lof.fit_predict(X)\n",
    "    anomalies = np.where(labels == -1)[0]\n",
    "    return anomalies\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def eval(y_true, anomalies):\n",
    "    y_pred = np.zeros_like(y_true)\n",
    "    y_pred[anomalies] = 1\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    return precision, recall, f1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465ca265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means:  precision = 1.0  recall = 0.5  F1 = 0.6666666666666666\n",
      "DBSCAN:   precision = 1.0  recall = 1.0  F1 = 1.0\n",
      "LOF:      precision = 1.0  recall = 1.0  F1 = 1.0\n"
     ]
    }
   ],
   "source": [
    "X, y_true = generate_sensor_data()\n",
    "\n",
    "anom_kmeans = detect_anomalies_kmeans(X, k=3, percentile=95)\n",
    "p_km, r_km, f_km = eval(y_true, anom_kmeans)\n",
    "\n",
    "anom_dbscan = detect_anomalies_dbscan(X, eps=15, min_samples=20)\n",
    "p_db, r_db, f_db = eval(y_true, anom_dbscan)\n",
    "\n",
    "anom_lof = detect_anomalies_lof(X, n_neighbors=20, contamination=0.1)\n",
    "p_lof, r_lof, f_lof = eval(y_true, anom_lof)\n",
    "\n",
    "print(\"K-Means:  precision =\", p_km, \" recall =\", r_km, \" F1 =\", f_km)\n",
    "print(\"DBSCAN:   precision =\", p_db, \" recall =\", r_db, \" F1 =\", f_db)\n",
    "print(\"LOF:      precision =\", p_lof, \" recall =\", r_lof, \" F1 =\", f_lof)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
